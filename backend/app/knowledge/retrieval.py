"""
çŸ¥è¯†åº“æ£€ç´¢æœåŠ¡
æ”¯æŒå‘é‡æ£€ç´¢ã€å…³é”®è¯æ£€ç´¢ã€æ··åˆæ£€ç´¢
"""
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pymilvus import connections, Collection, utility
from app.core.config import settings
from app.core.logger import logger


@dataclass
class SearchResult:
    """æ£€ç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    metadata: Dict[str, Any]
    source: str


class RetrievalService:
    """æ£€ç´¢æœåŠ¡"""
    
    def __init__(self):
        self._connected = False
    
    async def connect(self):
        """è¿æ¥Milvus"""
        if not self._connected:
            connections.connect(
                alias="default",
                host=settings.MILVUS_HOST,
                port=settings.MILVUS_PORT,
                user=settings.MILVUS_USER or None,
                password=settings.MILVUS_PASSWORD or None
            )
            self._connected = True
    
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self._connected:
            connections.disconnect("default")
            self._connected = False
    
    async def vector_search(
        self,
        collection_name: str,
        query_text: str = None,
        query_vector: List[float] = None,
        top_k: int = 10,
        score_threshold: float = 0.7,
        filter_expr: str = None
    ) -> List[Dict[str, Any]]:
        """
        å‘é‡æ£€ç´¢
        
        Args:
            collection_name: é›†åˆåç§°
            query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå°†è‡ªåŠ¨è½¬æ¢ä¸ºå‘é‡ï¼‰
            query_vector: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›æ•°é‡
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            filter_expr: è¿‡æ»¤è¡¨è¾¾å¼
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        logger.info(f"========== å¼€å§‹å‘é‡æ£€ç´¢ ==========")
        logger.info(f"Collection: {collection_name}")
        logger.info(f"æŸ¥è¯¢æ–‡æœ¬: {query_text[:100] if query_text else 'N/A'}...")
        logger.info(f"Top K: {top_k}, ç›¸ä¼¼åº¦é˜ˆå€¼: {score_threshold}")
        
        await self.connect()
        
        # å¦‚æœæä¾›çš„æ˜¯æ–‡æœ¬ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸ºå‘é‡
        if query_text and not query_vector:
            logger.info(f"å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡...")
            query_vector = await self._text_to_vector(query_text)
            logger.info(f"å‘é‡è½¬æ¢å®Œæˆï¼Œç»´åº¦: {len(query_vector)}")
        
        if not query_vector:
            raise ValueError("Must provide either query_text or query_vector")
        
        logger.info(f"åŠ è½½ Milvus Collection: {collection_name}")
        collection = Collection(collection_name)
        collection.load()
        
        # è·å–é›†åˆä¿¡æ¯
        num_entities = collection.num_entities
        logger.info(f"Collection ä¸­å…±æœ‰ {num_entities} æ¡å‘é‡è®°å½•")
        
        search_params = {
            "metric_type": "COSINE",
            "params": {"nprobe": 10}
        }
        
        logger.info(f"æ‰§è¡Œ Milvus å‘é‡æœç´¢ï¼ˆç›¸ä¼¼åº¦ç®—æ³•: COSINEï¼‰...")
        results = collection.search(
            data=[query_vector],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=filter_expr,
            output_fields=["content", "metadata", "source"]
        )
        
        logger.info(f"Milvus æ£€ç´¢å®Œæˆ")
        
        search_results = []
        for hits in results:
            logger.info(f"æ‰¾åˆ° {len(hits)} æ¡åŸå§‹ç»“æœ")
            for i, hit in enumerate(hits):
                if hit.score >= score_threshold:
                    search_results.append({
                        "id": str(hit.id),
                        "content": hit.entity.get("content", ""),
                        "score": float(hit.score),
                        "metadata": hit.entity.get("metadata", {}),
                        "source": hit.entity.get("source", "")
                    })
                    if i < 3:  # æ‰“å°å‰3æ¡ç»“æœ
                        content_preview = hit.entity.get("content", "")[:100].replace('\n', ' ')
                        logger.info(f"  ç»“æœ {i+1}: åˆ†æ•°={hit.score:.4f}, å†…å®¹={content_preview}...")
                else:
                    logger.debug(f"  ç»“æœ {i+1} è¢«è¿‡æ»¤ï¼ˆåˆ†æ•° {hit.score:.4f} < é˜ˆå€¼ {score_threshold}ï¼‰")
        
        logger.info(f"========== æ£€ç´¢å®Œæˆ ==========")
        logger.info(f"âœ… è¿‡æ»¤åè¿”å› {len(search_results)} æ¡ç»“æœ")
        logger.info(f"====================================")
        
        return search_results
    
    async def _text_to_vector(self, text: str) -> List[float]:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""
        try:
            from sentence_transformers import SentenceTransformer
            import time
            
            # å¦‚æœæ²¡æœ‰åŠ è½½æ¨¡å‹ï¼Œå…ˆåŠ è½½
            if not hasattr(self, '_embedding_model'):
                model_path = settings.EMBEDDING_MODEL or 'BAAI/bge-m3'
                logger.info(f"ğŸ”„ æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹: {model_path}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°è·¯å¾„
                import os
                if os.path.exists(model_path):
                    logger.info(f"ğŸ’¾ ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹: {model_path}")
                    start_time = time.time()
                    self._embedding_model = SentenceTransformer(
                        model_path,
                        device=settings.EMBEDDING_DEVICE or 'cpu'
                    )
                    load_time = time.time() - start_time
                    logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆè€—æ—¶: {load_time:.2f}sï¼‰")
                else:
                    logger.info(f"ğŸŒ ä» HuggingFace ä¸‹è½½æ¨¡å‹: {model_path}")
                    start_time = time.time()
                    self._embedding_model = SentenceTransformer(
                        model_path,
                        device=settings.EMBEDDING_DEVICE or 'cpu',
                        cache_folder=settings.EMBEDDING_CACHE_FOLDER
                    )
                    load_time = time.time() - start_time
                    logger.info(f"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆè€—æ—¶: {load_time:.2f}sï¼‰")
            
            # ç”Ÿæˆå‘é‡
            start_time = time.time()
            vector = self._embedding_model.encode(text, normalize_embeddings=True)
            encode_time = time.time() - start_time
            logger.info(f"ğŸ§¬ æ–‡æœ¬ç¼–ç å®Œæˆï¼ˆè€—æ—¶: {encode_time:.3f}s, ç»´åº¦: {len(vector)}ï¼‰")
            
            return vector.tolist()
        except Exception as e:
            logger.error(f"âŒ Embedding æ¨¡å‹åŠ è½½æˆ–ç¼–ç å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡ï¼ˆä»…ä¾›æµ‹è¯•ï¼‰
            return [0.0] * settings.EMBEDDING_DIMENSION
    
    async def keyword_search(
        self,
        collection_name: str,
        query_text: str,
        top_k: int = 10
    ) -> List[Dict[str, Any]]:
        """
        å…³é”®è¯æ£€ç´¢ (BM25)
        
        Args:
            collection_name: é›†åˆåç§°
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # ç®€å•å®ç°ï¼šä½¿ç”¨å‘é‡æ£€ç´¢ä½œä¸ºåå¤‡
        # TODO: å®ç°çœŸæ­£çš„ BM25 å…³é”®è¯æ£€ç´¢
        # å¯ä»¥ä½¿ç”¨ Elasticsearch æˆ– rank_bm25
        return await self.vector_search(
            collection_name=collection_name,
            query_text=query_text,
            top_k=top_k,
            score_threshold=0.0  # å…³é”®è¯æ£€ç´¢ä¸ä½¿ç”¨é˜ˆå€¼
        )
    
    async def hybrid_search(
        self,
        collection_name: str,
        query_text: str,
        top_k: int = 10,
        score_threshold: float = 0.7,
        vector_weight: float = 0.7,
        keyword_weight: float = 0.3
    ) -> List[Dict[str, Any]]:
        """
        æ··åˆæ£€ç´¢ (å‘é‡ + å…³é”®è¯)
        
        Args:
            collection_name: é›†åˆåç§°
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            vector_weight: å‘é‡æ£€ç´¢æƒé‡
            keyword_weight: å…³é”®è¯æ£€ç´¢æƒé‡
        
        Returns:
            èåˆåçš„æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # ç›®å‰ç®€åŒ–å®ç°ï¼šç›´æ¥ä½¿ç”¨å‘é‡æ£€ç´¢
        # TODO: å®ç°çœŸæ­£çš„æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + BM25ï¼‰
        return await self.vector_search(
            collection_name=collection_name,
            query_text=query_text,
            top_k=top_k,
            score_threshold=score_threshold
        )
    
    def _merge_results(
        self,
        vector_results: List[SearchResult],
        keyword_results: List[SearchResult],
        vector_weight: float,
        keyword_weight: float
    ) -> List[SearchResult]:
        """èåˆæ£€ç´¢ç»“æœ"""
        result_map: Dict[str, SearchResult] = {}
        
        # å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
        for r in vector_results:
            if r.id not in result_map:
                result_map[r.id] = SearchResult(
                    id=r.id,
                    content=r.content,
                    score=r.score * vector_weight,
                    metadata=r.metadata,
                    source=r.source
                )
            else:
                result_map[r.id].score += r.score * vector_weight
        
        # å¤„ç†å…³é”®è¯æ£€ç´¢ç»“æœ
        for r in keyword_results:
            if r.id not in result_map:
                result_map[r.id] = SearchResult(
                    id=r.id,
                    content=r.content,
                    score=r.score * keyword_weight,
                    metadata=r.metadata,
                    source=r.source
                )
            else:
                result_map[r.id].score += r.score * keyword_weight
        
        return list(result_map.values())
    
    async def add_texts(
        self,
        collection_name: str,
        texts: List[str],
        metadatas: List[Dict[str, Any]] = None
    ):
        """æ·»åŠ æ–‡æœ¬åˆ°é›†åˆ"""
        logger.info(f"========== å¼€å§‹å‘é‡åŒ–å­˜å‚¨ ==========")
        logger.info(f"é›†åˆåç§°: {collection_name}")
        logger.info(f"æ–‡æœ¬æ•°é‡: {len(texts)}")
        
        await self.connect()
        
        # ç”Ÿæˆ embeddings
        logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(texts)} ä¸ªå‘é‡...")
        vectors = []
        import time
        start_time = time.time()
        
        for i, text in enumerate(texts):
            vector = await self._text_to_vector(text)
            vectors.append(vector)
            if (i + 1) % 5 == 0 or (i + 1) == len(texts):
                logger.info(f"  è¿›åº¦: {i+1}/{len(texts)} ({(i+1)/len(texts)*100:.1f}%)")
        
        total_time = time.time() - start_time
        logger.info(f"å‘é‡ç”Ÿæˆå®Œæˆï¼ˆæ€»è€—æ—¶: {total_time:.2f}s, å¹³å‡: {total_time/len(texts):.3f}s/æ–‡æœ¬ï¼‰")
        
        # å‡†å¤‡æ•°æ®
        logger.info(f"å‡†å¤‡æ’å…¥æ•°æ®...")
        entities = [
            vectors,  # embedding field
            texts,    # content field
            metadatas if metadatas else [{} for _ in texts],  # metadata field
            [meta.get("source", "") for meta in (metadatas or [{} for _ in texts])]  # source field
        ]
        
        logger.info(f"å¼€å§‹æ’å…¥åˆ° Milvus Collection: {collection_name}")
        collection = Collection(collection_name)
        collection.insert(entities)
        logger.info(f"æ•°æ®æ’å…¥å®Œæˆï¼Œæ‰§è¡Œ flush...")
        collection.flush()
        logger.info(f"âœ… Flush å®Œæˆï¼")
        logger.info(f"========== å‘é‡åŒ–å­˜å‚¨å®Œæˆ ==========")
    
    async def rerank(
        self,
        query: str,
        documents: List[str],
        top_n: int = 5
    ) -> List[Dict[str, Any]]:
        """å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åº"""
        # TODO: é›†æˆ BGE-Reranker æ¨¡å‹
        # ç›®å‰ç›´æ¥è¿”å›åŸç»“æœ
        results = []
        for i, doc in enumerate(documents[:top_n]):
            results.append({
                "id": str(i),
                "content": doc,
                "score": 1.0 - (i * 0.1),  # æ¨¡æ‹Ÿåˆ†æ•°
                "metadata": {},
                "source": ""
            })
        return results
    
    async def search(
        self,
        collection_name: str,
        query: str,
        query_vector: List[float],
        mode: str = "hybrid",
        top_k: int = 10,
        threshold: float = 0.7
    ) -> List[SearchResult]:
        """
        ç»Ÿä¸€æ£€ç´¢æ¥å£
        
        Args:
            collection_name: é›†åˆåç§°
            query: æŸ¥è¯¢æ–‡æœ¬
            query_vector: æŸ¥è¯¢å‘é‡
            mode: æ£€ç´¢æ¨¡å¼ (vector/keyword/hybrid)
            top_k: è¿”å›æ•°é‡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if mode == "vector":
            return await self.vector_search(
                collection_name, query_vector, top_k, threshold
            )
        elif mode == "keyword":
            return await self.keyword_search(
                collection_name, query, top_k
            )
        else:  # hybrid
            return await self.hybrid_search(
                collection_name, query, query_vector, top_k, threshold
            )


class RerankService:
    """é‡æ’åºæœåŠ¡"""
    
    def __init__(self):
        self.model = None
    
    async def load_model(self):
        """åŠ è½½é‡æ’åºæ¨¡å‹"""
        # TODO: åŠ è½½BGE-Rerankeræ¨¡å‹
        # from FlagEmbedding import FlagReranker
        # self.model = FlagReranker('BAAI/bge-reranker-v2-m3')
        pass
    
    async def rerank(
        self,
        query: str,
        results: List[SearchResult],
        top_n: int = 5
    ) -> List[SearchResult]:
        """
        å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            results: æ£€ç´¢ç»“æœ
            top_n: è¿”å›æ•°é‡
        
        Returns:
            é‡æ’åºåçš„ç»“æœ
        """
        if not self.model:
            # å¦‚æœæ²¡æœ‰åŠ è½½æ¨¡å‹ï¼Œç›´æ¥è¿”å›åŸç»“æœ
            return results[:top_n]
        
        # TODO: ä½¿ç”¨æ¨¡å‹è¿›è¡Œé‡æ’åº
        # pairs = [[query, r.content] for r in results]
        # scores = self.model.compute_score(pairs)
        # ...
        
        return results[:top_n]


# å…¨å±€å®ä¾‹
retrieval_service = RetrievalService()
rerank_service = RerankService()
